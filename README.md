# Graph App Demo <!-- omit in toc -->

- [1. Disclaimer](#1-disclaimer)
- [2. Application](#2-application)
  - [2.1. Installing dependencies](#21-installing-dependencies)
  - [2.2. Run the web application](#22-run-the-web-application)
  - [2.3. Generating test data](#23-generating-test-data)
    - [2.3.1. Seed File Generation](#231-seed-file-generation)
    - [2.3.2. Data generation](#232-data-generation)
  - [Sample data](#sample-data)
    - [Sample User](#sample-user)
    - [Sample Role](#sample-role)
    - [Sample Bucket](#sample-bucket)
    - [Sample Payload](#sample-payload)
  - [Graph Lookup](#graph-lookup)
- [4. Application Template Generation](#4-application-template-generation)
  - [4.1. React + Vite](#41-react--vite)

## 1. Disclaimer

> THIS SOFTWARE IS PROVIDED ***AS IS*** AND ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE SUPPLIERS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

The code provided here is Proof-of-Concept grade and is ***not*** Production-grade. Furthermore, the schema design applied to the data stored on MongoDB may not be in the most desirable/recommended format. The point of this application is to showcase the ability of MongoDB's `graphLookup`. Refer to the [graphLookup Aggregation Stage Documentation](https://www.mongodb.com/docs/manual/reference/operator/aggregation/graphLookup/) from more information.

## 2. Application

The application is split into three distinct parts,

1. The frontend React (plus ReactFlow) application in ```/src```
2. The server application that exposes an HTTP api for the frontend to load the necessary data from MongoDB. Code for the server is found in ```/src/server/```
3. The data generation scripts used to create test data found in ```datagen```

### 2.1. Installing dependencies

```BASH
npm install
```

### 2.2. Run the web application

```BASH
npm run dev
```

> Before executing,
>
> - check the MongoDB URI is correct in `./src/server/mongo.js`
> - check the MongoDB instance has the required data
> - make sure the necessary indexes on the collection are created

### 2.3. Generating test data

Test data generation is split into two steps,

1. Generation of a seed file that contains the "assets" to be used when generating and inserting data into MongoDB.
2. Generation of data based on the seed file and insertion into MongoDB.

#### 2.3.1. Seed File Generation

The scope of the seed file is to seperate the process of generating assets from creating connections between "assets" and inserting all data into MongoDB. The seed file will have this format,

``` JSON
{
    "users" : [],
    "roles" : [],
    "permissions" : ["READ", "WRITE", "DELETE", "MANAGE"],
    "buckets" : [],
    "payloads" : ["FINANCIAL", "PII", "CREDENTIALS"]
}
```

In other words, `users`, `roles`, and `buckets` will be generated by the seed generation process, while `permissions` and `payloads` will be fixed to the supplied arrays.

The output of the seed generation process can be controlled by directly editting `datagen/gendata-seed.js`. The following are the relevant fields,

- `noOfUsers` - the number of `user` assets to be created.
- `noOfRoles` - the number of `role` assets to be created. Note that **389** is the largest possible number, imposed by the underlying chance.js library.
- `noOfBuckets` - the number of `bucket` assets to be created. Note that **947** is the largest possible number, imposed by the underlying chance.js library.
- `result` - controls the structure of the seed file.
- `outputFile` - the output seed file.

To generate a seed file, run the following

``` BASH
npm run gendata-seed
```

#### 2.3.2. Data generation

Data generation works on the input seed file generated using ```gendata-seed``` explained above.

The process creates data in batches, where each batch is based on the following rules,

- For all `users` in the Seed File
  - Create a `user`
  - Link `user` to a random number of buckets with a maximum of `maxBucketPerUserOrRole`
    - For each link, assign a random `permission` extracted from the seed file
  - Link `user` to a random number of `role` with a maximum of `maxRolePerUser`

- For all `roles` in the Seed File
  - Create a `role`
  - Link `role` to a random number of buckets with a maximum of `maxBucketPerUserOrRole`
    - For each link, assign a random `permission` extracted from the seed file
  - NOTE: the process is adding `roles` to `users` only (and not other `roles`) as otherwise we get state explosion in the random data generation.

- For all `buckets` in the Seed File
  - Create `bucket`
  - Link `bucket` to a random number of payload types

- For all `payloads` (type) in the Seed File
  - Create a `payload` (type)

- Thus, data is linked uni directional as follows,

``` TEXT
 +--------+      Has Access to      +---------+  Contains Payload  +-----------+
 |        |      with Permission    |         |         Type       |           |
 |  User  +------------------------>|  Bucket +------------------->|  Payload  |
 |        |                         |         |                    |           |
 +----+---+                         +---------+                    +-----------+
      |                                  ^
      |                                  |
      |             +---------+          | Has Access To
      |             |         |          | with Permission
      +-------------+  Role   +----------+
        Is Assigned |         |
                    +---------+

 Made with https://asciiflow.com/
```

The process can be controlled by directly editting `datagen/gendata.js`. The following are the relevant fields,

- `seedInputFile` - the input seed file generated using ```gendata-seed``` explained above
- `maxBucketPerUserOrRole` - the maximum number of links created between a `user` or a `role` to `buckets`
- maxRolePerUser - the maximum number of links created between a `user` and a `role`
- `batches` - the number of batches to create i.e. defines the number of times the insertion process described above is repeated. Note that each batch will create unique assets by appending the batch number to the asset name.
- `uri` - the URI to connect to MongoDB. This is were all the data will be inserted.

To generate data in MongoDB, run the following

```BASH
npm run gendata
```

### Sample data
The data inserted into MongoDB will have this format.

> NOTE: The presented format might not be production grade and further optimisations may be performed on it.

#### Sample User

```JSON
{
  "_id": { "t": "USER", "n": "Ruby Soto" },
  "type": "USER",
  "name": "Ruby Soto",
  "relations": [
    { "r": { "t": "BUCKET", "n": "Healthsouth Corp" }, "d": "DELETE" },
    { "r": { "t": "BUCKET", "n": "Best Buy Co., Inc." }, "d": "MANAGE" },
    {
      "r": { "t": "BUCKET", "n": "Allmerica Financial Corporation" },
      "d": "MANAGE"
    },
    { "r": { "t": "ROLE", "n": "Freelance Writer" }, "d": null },
    { "r": { "t": "ROLE", "n": "International Acct." }, "d": null },
    { "r": { "t": "ROLE", "n": "Career Counselor" }, "d": null },
    { "r": { "t": "ROLE", "n": "Property Manager" }, "d": null },
    { "r": { "t": "ROLE", "n": "TV Programmer" }, "d": null }
  ]
}
```

#### Sample Role

```JSON
{
  "_id": { "t": "ROLE", "n": "Academic Team" },
  "type": "ROLE",
  "name": "Academic Team",
  "relations": [
    { "r": { "t": "BUCKET", "n": "Coca-Cola Enterprises Inc." }, "d": "WRITE" },
    { "r": { "t": "BUCKET", "n": "Mohawk Industries Inc." }, "d": "READ" },
    {
      "r": { "t": "BUCKET", "n": "Citizens Communications Co." },
      "d": "MANAGE"
    },
    { "r": { "t": "BUCKET", "n": "Owens & Minor Inc." }, "d": "READ" }
  ]
}
```

#### Sample Bucket

```JSON
{
  "_id": { "t": "BUCKET", "n": "3Com Corp" },
  "type": "BUCKET",
  "name": "3Com Corp",
  "relations": [{ "r": { "t": "PAYLOAD", "n": "PII" }, "d": null }]
}
```

#### Sample Payload

> NOTE: PAYLOAD assets do not have any relations

```JSON
{
  "_id": { "t": "PAYLOAD", "n": "CREDENTIALS" },
  "type": "PAYLOAD",
  "name": "CREDENTIALS",
  "relations": []
}
```


### Graph Lookup

This is the core of the POC - using `graphLookup` to render a graph from the generated data. This is achieved using the Aggregation Pipeline defined in `./src/server/mongo.js`.

The following is an example pipeline that is executed to find the graph of assets related to `Toro Company`.

> Note: The presented aggregation pipeline might not be production grade and further optimisations may be performed on it.

```JSON
[
  {                                             //1️⃣ match on asset to search for
    "$match": { "name": "Toro Company" } 
  },     
  {                                             //2️⃣ perform graph lookup - forward search
    "$graphLookup": {
      "from": "data",
      "startWith": "$_id",
      "connectFromField": "relations.r",
      "connectToField": "_id",
      "as": "connections",
      "depthField": "depth"
    }
  },
  { "$unwind": "$connections" },                //3️⃣ unwind connections
  {                                             //4️⃣ replace root
    "$replaceRoot": { "newRoot": "$connections" } 
  },
  {                                             //5️⃣ unwind relations
    "$unwind": { "path": "$relations", "preserveNullAndEmptyArrays": true }
  },
  {                                             //6️⃣ union with reverse lookup
    "$unionWith": {
      "coll": "data",
      "pipeline": [
        {                                       //6️⃣➡️1️⃣ match on asset to search for
            "$match": { "name": "Toro Company" } 
        },
        {                                       //6️⃣➡️2️⃣ perform graph lookup - reverse search
          "$graphLookup": {
            "from": "data",
            "startWith": "$_id",
            "connectFromField": "_id",
            "connectToField": "relations.r",
            "as": "connections",
            "depthField": "depth"
          }
        },
        { "$unwind": "$connections" },          //6️⃣➡️3️⃣ unwind connections
        {                                       //6️⃣➡️4️⃣ replace root
            "$replaceRoot": { "newRoot": "$connections" } 
        },
        {                                       //6️⃣➡️5️⃣ unwind relations
          "$unwind": { "path": "$relations", "preserveNullAndEmptyArrays": true }
        }
      ]
    }
  },
  {                                             //7️⃣ group all assets into one document with the desired final structure
    "$group": {
      "_id": null,
      "vertices": { "$addToSet": { "id": "$name", "data": { "label": "$name" } } },
      "edges": {
        "$addToSet": {
          "source": "$name",
          "target": "$relations.r.n",
          "type": "edgeType",
          "label": "$relations.d"
        }
      }
    }
  },
  {                                             //8️⃣ add the search asset name to the result
    "$set": { "assetName": "Toro Company" } 
  },
  {                                             //9️⃣ remove the _id field 
    "$project": { "_id": 0 } 
  }
]
```

The steps performed by the pipeline are outlined below

- Step 1️⃣: match on asset to search for
  - This defines the starting point for our search
- Step 2️⃣: perform graph lookup - forward search
  - During this stage, the forward connections with the searched asset are found. The search is performed in a recursive manner where the `_id` of the node found in step 1️⃣ is matched with `_id` of a start document in the collection. Once this is matched, a recursive search for each unique element in `relations.r` is again performed against `_id`. The result of this `graphLookup` operation is saved in `connections`.
- Step 3️⃣, 4️⃣, 5️⃣
  - Transform the output so that there is a single document per link between assets.
- Step 6️⃣: union with reverse lookup
  - Sub-step 6️⃣➡️1️⃣ match on asset to search for
  - Sub-step 6️⃣➡️2️⃣ perform graph lookup - reverse search
    - During this stage, the reverse connections with the searched asset are found. Note that the reverse connections are not explicitly defined in the document, so the `graphLookup` is performed in the opposite manner. The search is performed in a recursive manner where the `_id` of the node found in step 1️⃣ is matched with all possible matches in `relations.r`. Once the initial documents for our reverse search are found, a recursive search for the `_id` is again performed against `relations.r`. The result of this `graphLookup` operation is saved in `connections`.
  - Sub-steps 6️⃣➡️3️⃣, 6️⃣➡️4️⃣, 6️⃣➡️5️⃣
    - Transform the output so that there is a single document per link between assets.
- Step 7️⃣: group all assets into one document with the desired final structure
  - This step merges all the documents found so far that represents a one way relationship (i.e. A->B). The output format of this stage is entirely dictated by the application requirements. In this case, this is dictated by the data format required by ReactFlow. 
- Steps 8️⃣, 9️⃣: Other minor modifications to the final result


## 4. Application Template Generation

The application template was generated using vite.

```BASH
npm create vite@latest graph-app -- --template react
```

The subsection was generated automatically when the template was requested.

### 4.1. React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh
